{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proved-philadelphia",
   "metadata": {},
   "source": [
    "# Beer prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-integral",
   "metadata": {},
   "source": [
    "!python -c \"import pandas as pd; print(pd.__version__)\"## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reduced-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import pandas as pd; print(pd.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brief-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-letter",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lasting-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load magic command for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "crucial-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off table squishing\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(\"../data/raw/beer_reviews.csv\")\n",
    "\n",
    "# Check data\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-mustang",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intellectual-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Dictionary\n",
    "# Direct copy & paste from Assignment 2 Brief\n",
    "\n",
    "DataDict = \\\n",
    "    { \"brewery_id\": \"Identifier of brewery\"\n",
    "    , \"brewery_name\": \"Name of brewery\"\n",
    "    , \"review_time\": \"Timestamp of review\"\n",
    "    , \"review_overall\": \"Overall score given by reviewer\"\n",
    "    , \"review_aroma\": \"Score given by reviewer regarding beer aroma\"\n",
    "    , \"review_appearance\": \"Score given by reviewer regarding beer appearance\"\n",
    "    , \"review_profilename\": \"Profile name of reviewer\"\n",
    "    , \"review_palate\": \"Score given by reviewer regarding beer palate\"\n",
    "    , \"review_taste\": \"Score given by reviewer regarding beer taste\"\n",
    "    , \"beer_style (target)\": \"Type of beer\"\n",
    "    , \"beer_name\": \"Name of beer\"\n",
    "    , \"beer_abv\": \"Alcohol by volume measure\"\n",
    "    , \"beer_beerid\": \"Identifier of beer\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hundred-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1586614 entries, 0 to 1586613\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   brewery_id          1586614 non-null  int64  \n",
      " 1   brewery_name        1586599 non-null  object \n",
      " 2   review_time         1586614 non-null  int64  \n",
      " 3   review_overall      1586614 non-null  float64\n",
      " 4   review_aroma        1586614 non-null  float64\n",
      " 5   review_appearance   1586614 non-null  float64\n",
      " 6   review_profilename  1586266 non-null  object \n",
      " 7   beer_style          1586614 non-null  object \n",
      " 8   review_palate       1586614 non-null  float64\n",
      " 9   review_taste        1586614 non-null  float64\n",
      " 10  beer_name           1586614 non-null  object \n",
      " 11  beer_abv            1518829 non-null  float64\n",
      " 12  beer_beerid         1586614 non-null  int64  \n",
      "dtypes: float64(6), int64(3), object(4)\n",
      "memory usage: 157.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "communist-techno",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.518829e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.130099e+03</td>\n",
       "      <td>1.224089e+09</td>\n",
       "      <td>3.815581e+00</td>\n",
       "      <td>3.735636e+00</td>\n",
       "      <td>3.841642e+00</td>\n",
       "      <td>3.743701e+00</td>\n",
       "      <td>3.792860e+00</td>\n",
       "      <td>7.042387e+00</td>\n",
       "      <td>2.171279e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.578104e+03</td>\n",
       "      <td>7.654427e+07</td>\n",
       "      <td>7.206219e-01</td>\n",
       "      <td>6.976167e-01</td>\n",
       "      <td>6.160928e-01</td>\n",
       "      <td>6.822184e-01</td>\n",
       "      <td>7.319696e-01</td>\n",
       "      <td>2.322526e+00</td>\n",
       "      <td>2.181834e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.406720e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.430000e+02</td>\n",
       "      <td>1.173224e+09</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>5.200000e+00</td>\n",
       "      <td>1.717000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>1.239203e+09</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.500000e+00</td>\n",
       "      <td>1.390600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.372000e+03</td>\n",
       "      <td>1.288568e+09</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>8.500000e+00</td>\n",
       "      <td>3.944100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.800300e+04</td>\n",
       "      <td>1.326285e+09</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.770000e+01</td>\n",
       "      <td>7.731700e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brewery_id   review_time  review_overall  review_aroma  \\\n",
       "count  1.586614e+06  1.586614e+06    1.586614e+06  1.586614e+06   \n",
       "mean   3.130099e+03  1.224089e+09    3.815581e+00  3.735636e+00   \n",
       "std    5.578104e+03  7.654427e+07    7.206219e-01  6.976167e-01   \n",
       "min    1.000000e+00  8.406720e+08    0.000000e+00  1.000000e+00   \n",
       "25%    1.430000e+02  1.173224e+09    3.500000e+00  3.500000e+00   \n",
       "50%    4.290000e+02  1.239203e+09    4.000000e+00  4.000000e+00   \n",
       "75%    2.372000e+03  1.288568e+09    4.500000e+00  4.000000e+00   \n",
       "max    2.800300e+04  1.326285e+09    5.000000e+00  5.000000e+00   \n",
       "\n",
       "       review_appearance  review_palate  review_taste      beer_abv  \\\n",
       "count       1.586614e+06   1.586614e+06  1.586614e+06  1.518829e+06   \n",
       "mean        3.841642e+00   3.743701e+00  3.792860e+00  7.042387e+00   \n",
       "std         6.160928e-01   6.822184e-01  7.319696e-01  2.322526e+00   \n",
       "min         0.000000e+00   1.000000e+00  1.000000e+00  1.000000e-02   \n",
       "25%         3.500000e+00   3.500000e+00  3.500000e+00  5.200000e+00   \n",
       "50%         4.000000e+00   4.000000e+00  4.000000e+00  6.500000e+00   \n",
       "75%         4.000000e+00   4.000000e+00  4.500000e+00  8.500000e+00   \n",
       "max         5.000000e+00   5.000000e+00  5.000000e+00  5.770000e+01   \n",
       "\n",
       "        beer_beerid  \n",
       "count  1.586614e+06  \n",
       "mean   2.171279e+04  \n",
       "std    2.181834e+04  \n",
       "min    3.000000e+00  \n",
       "25%    1.717000e+03  \n",
       "50%    1.390600e+04  \n",
       "75%    3.944100e+04  \n",
       "max    7.731700e+04  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data profile\n",
    "\n",
    "# Create profile report\n",
    "profile = ProfileReport(df, title=\"Profile Report\", minimal=True)\n",
    "# Export\n",
    "profile.to_file('../reports/InitialReport.html')\n",
    "# View\n",
    "#profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-guinea",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "atlantic-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df and save it into a variable called df_cleaned\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "timely-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(['brewery_id', 'review_time', 'review_overall', 'review_profilename', 'beer_name', 'beer_abv', 'beer_beerid'], axis=1)\n",
    "df_cleaned = df_cleaned.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "packed-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "brewery_name_list = df_cleaned['brewery_name'].unique().tolist()\n",
    "brewery_name_list = np.sort(brewery_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "modern-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_style_list = df_cleaned['beer_style'].unique().tolist()\n",
    "beer_style_list = np.sort(beer_style_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "empty-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary called cats_dict that contains the categorical variables as keys and their respective values sorted in ascending order\n",
    "cats_dict = {\n",
    "    'brewery_name': brewery_name_list,\n",
    "    'beer_style': beer_style_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "imperial-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler and OrdinalEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "three-portal",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-cf08735da040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcats_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcol_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_cleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    759\u001b[0m                             f\"got {self.unknown_value}.\")\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'use_encoded_value'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[0;32m     78\u001b[0m             X, force_all_finite=force_all_finite)\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 raise ValueError(\"Shape mismatch: if categories is an array,\"\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Iterate through the elements of cast_dict, instantiate an OrdinalEncoder() and transform the values of each column with this encoder\n",
    "for col, cats in cats_dict.items():\n",
    "    col_encoder = OrdinalEncoder(categories=cats)\n",
    "    df_cleaned[col] = col_encoder.fit_transform(df_cleaned[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "organized-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list called num_cols that contains all numeric columns\n",
    "num_cols = ['review_aroma', 'review_appearance', 'review_palate', 'review_taste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler and called it sc\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the numeric feature of X_train_cleaned and replace the data into it\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "brown-customs",
   "metadata": {},
   "source": [
    "#Convert the column evaluation as integer\n",
    "df_cleaned['beer_style'] = df_cleaned['beer_style'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sets_by_time(df, target_col, test_ratio=0.2):\n",
    "    df_copy = df.copy()\n",
    "    target = df_copy.pop(target_col)\n",
    "    cutoff = int(len(target) / 5)\n",
    "    \n",
    "    X_train, y_train = subset_x_y(target=target, features=df_copy, start_index=0, end_index=-cutoff*2)\n",
    "    X_val, y_val     = subset_x_y(target=target, features=df_copy, start_index=-cutoff*2, end_index=-cutoff)\n",
    "    X_test, y_test   = subset_x_y(target=target, features=df_copy, start_index=-cutoff, end_index=len(target))\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sets(X_train=None, y_train=None, X_val=None, y_val=None, X_test=None, y_test=None, path='../data/processed/'):\n",
    "    import numpy as np\n",
    "\n",
    "    if X_train is not None:\n",
    "      np.save(f'{path}X_train', X_train)\n",
    "    if X_val is not None:\n",
    "      np.save(f'{path}X_val',   X_val)\n",
    "    if X_test is not None:\n",
    "      np.save(f'{path}X_test',  X_test)\n",
    "    if y_train is not None:\n",
    "      np.save(f'{path}y_train', y_train)\n",
    "    if y_val is not None:\n",
    "      np.save(f'{path}y_val',   y_val)\n",
    "    if y_test is not None:\n",
    "      np.save(f'{path}y_test',  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.data.sets import split_sets_by_time, save_sets\n",
    "# Split data into training and testing with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(X, target_col='beer_style', test_ratio=0.2, to_numpy=True)\n",
    "\n",
    "# Save sets to folder\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import this class from src/models/pytorch and convert all sets to PytorchDataset\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NullModel from src.models.null\n",
    "#from src.models.null import NullModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NullModel:\n",
    "    \"\"\"\n",
    "    Class used as baseline model for both regression and classification\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Type of ML problem (default regression)\n",
    "    y : Numpy Array-like\n",
    "        Target variable\n",
    "    pred_value : Float\n",
    "        Value to be used for prediction\n",
    "    preds : Numpy Array\n",
    "        Predicted array\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(y)\n",
    "        Store the input target variable and calculate the predicted value to be used based on the problem type\n",
    "    get_length\n",
    "        Calculate the number of observations from the target variable\n",
    "    predict(y)\n",
    "        Generate the predictions\n",
    "    fit_predict(y)\n",
    "        Perform a fit followed by predict\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    def __init__(self, target_type: str = \"regression\"):\n",
    "        self.target_type = target_type\n",
    "        self.y = None\n",
    "        self.pred_value = None\n",
    "        self.preds = None\n",
    "        \n",
    "    def fit(self, y):\n",
    "        self.y = y\n",
    "        if self.target_type == \"regression\":\n",
    "            self.pred_value = y.mean()\n",
    "        else:\n",
    "            from scipy.stats import mode\n",
    "            self.pred_value = mode(y)[0][0]\n",
    "            \n",
    "    def get_length(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def predict(self, y):\n",
    "        self.preds = np.full((self.get_length(), 1), self.pred_value)\n",
    "        return self.preds\n",
    "    \n",
    "    def fit_predict(self, y):\n",
    "        self.fit(y)\n",
    "        return self.predict(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a NullModel and call .fit_predict() on the training target to extract your predictions into a variable called y_base\n",
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import print_class_perf from src.models.performance\n",
    "#from src.models.performance import print_class_perf\n",
    "\n",
    "def print_class_perf(y_preds, y_actuals, set_name=None, average='binary'):\n",
    "    \"\"\"Print the Accuracy and F1 score for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "    average : str\n",
    "        Parameter  for F1-score averaging\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    print(f\"Accuracy {set_name}: {accuracy_score(y_actuals, y_preds)}\")\n",
    "    print(f\"F1 {set_name}: {f1_score(y_actuals, y_preds, average=average)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task: Print the classification metrics for this baseline model\n",
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-insulation",
   "metadata": {},
   "source": [
    "## Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class called PytorchMultiClass that inherits from nn.Module\n",
    "class PytorchMultiClass(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchMultiClass, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 32)\n",
    "        self.layer_out = nn.Linear(32, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)), training=self.training)\n",
    "        x = self.layer_out(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature and save it into a variable called model\n",
    "#from src.models.pytorch import PytorchMultiClass\n",
    "\n",
    "class PytorchMultiClass(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchMultiClass, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 32)\n",
    "        self.layer_out = nn.Linear(32, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)), training=self.training)\n",
    "        x = self.layer_out(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to use the device available\n",
    "#from src.models.pytorch import get_device\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the architecture of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-structure",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a nn.CrossEntropyLoss() and save it into a variable called criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a torch.optim.Adam() optimizer with the model's parameters and 0.1 as learning rate and save it into a variable called optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called train_classification() that will perform forward and back propagation and calculate loss and Accuracy scores\n",
    "def train_classification(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, generate_batch=None):\n",
    "    \"\"\"Train a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class.long())\n",
    "\n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate global accuracy\n",
    "        train_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), train_acc / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called test_classification() that will perform forward and calculate loss and accuracy scores\n",
    "def test_classification(test_data, model, criterion, batch_size, device, generate_batch=None):\n",
    "    \"\"\"Calculate performance of a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class.long())\n",
    "\n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            test_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    return test_loss / len(test_data), test_acc / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 variables called N_EPOCHS and BATCH_SIZE that will take respectively 50 and 32 as values\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model into the models folder\n",
    "torch.save(model, \"../models/pytorch_beer_prediction.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the model performance on the testing set and print its scores\n",
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
