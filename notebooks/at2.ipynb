{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "persistent-conviction",
   "metadata": {},
   "source": [
    "# Beer prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-publicity",
   "metadata": {},
   "source": [
    "!python -c \"import pandas as pd; print(pd.__version__)\"## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "integral-architect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import pandas as pd; print(pd.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regular-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-greek",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load magic command for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggregate-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off table squishing\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(\"../data/raw/beer_reviews.csv\")\n",
    "\n",
    "# Check data\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-irrigation",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "devoted-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Dictionary\n",
    "# Direct copy & paste from Assignment 2 Brief\n",
    "\n",
    "DataDict = \\\n",
    "    { \"brewery_id\": \"Identifier of brewery\"\n",
    "    , \"brewery_name\": \"Name of brewery\"\n",
    "    , \"review_time\": \"Timestamp of review\"\n",
    "    , \"review_overall\": \"Overall score given by reviewer\"\n",
    "    , \"review_aroma\": \"Score given by reviewer regarding beer aroma\"\n",
    "    , \"review_appearance\": \"Score given by reviewer regarding beer appearance\"\n",
    "    , \"review_profilename\": \"Profile name of reviewer\"\n",
    "    , \"review_palate\": \"Score given by reviewer regarding beer palate\"\n",
    "    , \"review_taste\": \"Score given by reviewer regarding beer taste\"\n",
    "    , \"beer_style (target)\": \"Type of beer\"\n",
    "    , \"beer_name\": \"Name of beer\"\n",
    "    , \"beer_abv\": \"Alcohol by volume measure\"\n",
    "    , \"beer_beerid\": \"Identifier of beer\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_profilename</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1234817823</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>stcules</td>\n",
       "      <td>Hefeweizen</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Sausa Weizen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1235915097</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>stcules</td>\n",
       "      <td>English Strong Ale</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Red Moon</td>\n",
       "      <td>6.2</td>\n",
       "      <td>48213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1235916604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>stcules</td>\n",
       "      <td>Foreign / Export Stout</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Black Horse Black Beer</td>\n",
       "      <td>6.5</td>\n",
       "      <td>48215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10325</td>\n",
       "      <td>Vecchio Birraio</td>\n",
       "      <td>1234725145</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>stcules</td>\n",
       "      <td>German Pilsener</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sausa Pils</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075</td>\n",
       "      <td>Caldera Brewing Company</td>\n",
       "      <td>1293735206</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>johnmichaelsen</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Cauldron DIPA</td>\n",
       "      <td>7.7</td>\n",
       "      <td>64883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brewery_id             brewery_name  review_time  review_overall  \\\n",
       "0       10325          Vecchio Birraio   1234817823             1.5   \n",
       "1       10325          Vecchio Birraio   1235915097             3.0   \n",
       "2       10325          Vecchio Birraio   1235916604             3.0   \n",
       "3       10325          Vecchio Birraio   1234725145             3.0   \n",
       "4        1075  Caldera Brewing Company   1293735206             4.0   \n",
       "\n",
       "   review_aroma  review_appearance review_profilename  \\\n",
       "0           2.0                2.5            stcules   \n",
       "1           2.5                3.0            stcules   \n",
       "2           2.5                3.0            stcules   \n",
       "3           3.0                3.5            stcules   \n",
       "4           4.5                4.0     johnmichaelsen   \n",
       "\n",
       "                       beer_style  review_palate  review_taste  \\\n",
       "0                      Hefeweizen            1.5           1.5   \n",
       "1              English Strong Ale            3.0           3.0   \n",
       "2          Foreign / Export Stout            3.0           3.0   \n",
       "3                 German Pilsener            2.5           3.0   \n",
       "4  American Double / Imperial IPA            4.0           4.5   \n",
       "\n",
       "                beer_name  beer_abv  beer_beerid  \n",
       "0            Sausa Weizen       5.0        47986  \n",
       "1                Red Moon       6.2        48213  \n",
       "2  Black Horse Black Beer       6.5        48215  \n",
       "3              Sausa Pils       5.0        47969  \n",
       "4           Cauldron DIPA       7.7        64883  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stylish-order",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1586614 entries, 0 to 1586613\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   brewery_id          1586614 non-null  int64  \n",
      " 1   brewery_name        1586599 non-null  object \n",
      " 2   review_time         1586614 non-null  int64  \n",
      " 3   review_overall      1586614 non-null  float64\n",
      " 4   review_aroma        1586614 non-null  float64\n",
      " 5   review_appearance   1586614 non-null  float64\n",
      " 6   review_profilename  1586266 non-null  object \n",
      " 7   beer_style          1586614 non-null  object \n",
      " 8   review_palate       1586614 non-null  float64\n",
      " 9   review_taste        1586614 non-null  float64\n",
      " 10  beer_name           1586614 non-null  object \n",
      " 11  beer_abv            1518829 non-null  float64\n",
      " 12  beer_beerid         1586614 non-null  int64  \n",
      "dtypes: float64(6), int64(3), object(4)\n",
      "memory usage: 157.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "objective-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "      <td>1.518829e+06</td>\n",
       "      <td>1.586614e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.130099e+03</td>\n",
       "      <td>1.224089e+09</td>\n",
       "      <td>3.815581e+00</td>\n",
       "      <td>3.735636e+00</td>\n",
       "      <td>3.841642e+00</td>\n",
       "      <td>3.743701e+00</td>\n",
       "      <td>3.792860e+00</td>\n",
       "      <td>7.042387e+00</td>\n",
       "      <td>2.171279e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.578104e+03</td>\n",
       "      <td>7.654427e+07</td>\n",
       "      <td>7.206219e-01</td>\n",
       "      <td>6.976167e-01</td>\n",
       "      <td>6.160928e-01</td>\n",
       "      <td>6.822184e-01</td>\n",
       "      <td>7.319696e-01</td>\n",
       "      <td>2.322526e+00</td>\n",
       "      <td>2.181834e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.406720e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.430000e+02</td>\n",
       "      <td>1.173224e+09</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>5.200000e+00</td>\n",
       "      <td>1.717000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>1.239203e+09</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.500000e+00</td>\n",
       "      <td>1.390600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.372000e+03</td>\n",
       "      <td>1.288568e+09</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>8.500000e+00</td>\n",
       "      <td>3.944100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.800300e+04</td>\n",
       "      <td>1.326285e+09</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.770000e+01</td>\n",
       "      <td>7.731700e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brewery_id   review_time  review_overall  review_aroma  \\\n",
       "count  1.586614e+06  1.586614e+06    1.586614e+06  1.586614e+06   \n",
       "mean   3.130099e+03  1.224089e+09    3.815581e+00  3.735636e+00   \n",
       "std    5.578104e+03  7.654427e+07    7.206219e-01  6.976167e-01   \n",
       "min    1.000000e+00  8.406720e+08    0.000000e+00  1.000000e+00   \n",
       "25%    1.430000e+02  1.173224e+09    3.500000e+00  3.500000e+00   \n",
       "50%    4.290000e+02  1.239203e+09    4.000000e+00  4.000000e+00   \n",
       "75%    2.372000e+03  1.288568e+09    4.500000e+00  4.000000e+00   \n",
       "max    2.800300e+04  1.326285e+09    5.000000e+00  5.000000e+00   \n",
       "\n",
       "       review_appearance  review_palate  review_taste      beer_abv  \\\n",
       "count       1.586614e+06   1.586614e+06  1.586614e+06  1.518829e+06   \n",
       "mean        3.841642e+00   3.743701e+00  3.792860e+00  7.042387e+00   \n",
       "std         6.160928e-01   6.822184e-01  7.319696e-01  2.322526e+00   \n",
       "min         0.000000e+00   1.000000e+00  1.000000e+00  1.000000e-02   \n",
       "25%         3.500000e+00   3.500000e+00  3.500000e+00  5.200000e+00   \n",
       "50%         4.000000e+00   4.000000e+00  4.000000e+00  6.500000e+00   \n",
       "75%         4.000000e+00   4.000000e+00  4.500000e+00  8.500000e+00   \n",
       "max         5.000000e+00   5.000000e+00  5.000000e+00  5.770000e+01   \n",
       "\n",
       "        beer_beerid  \n",
       "count  1.586614e+06  \n",
       "mean   2.171279e+04  \n",
       "std    2.181834e+04  \n",
       "min    3.000000e+00  \n",
       "25%    1.717000e+03  \n",
       "50%    1.390600e+04  \n",
       "75%    3.944100e+04  \n",
       "max    7.731700e+04  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "smoking-lodge",
   "metadata": {},
   "source": [
    "# View data profile\n",
    "\n",
    "# Create profile report\n",
    "profile = ProfileReport(df, title=\"Profile Report\", minimal=True)\n",
    "# Export\n",
    "profile.to_file('../reports/InitialReport.html')\n",
    "# View\n",
    "#profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-centre",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "breeding-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df and save it into a variable called df_cleaned\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fabulous-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(['brewery_id', 'review_time', 'review_overall', 'review_profilename', 'beer_name', 'beer_abv', 'beer_beerid'], axis=1)\n",
    "df_cleaned = df_cleaned.dropna(axis=0) #'inplace=True' instead of 'axis=0'?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "corresponding-studio",
   "metadata": {},
   "source": [
    "beer_list = []\n",
    "for x in df_cleaned['beer_style']:\n",
    "    if x not in beer_list:\n",
    "        beer_list.append(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "southwest-album",
   "metadata": {},
   "source": [
    "brewery_list = []\n",
    "for x in df_cleaned['brewery_name']:\n",
    "    if x not in brewery_list:\n",
    "        brewery_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "prescribed-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_set = set(df_cleaned['beer_style'])\n",
    "beer_list = list(beer_set)\n",
    "brewery_set = set(df_cleaned['brewery_name'])\n",
    "brewer_list = list(brewery_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "explicit-tiffany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stretch-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_dict = {\n",
    "    'beer_style': [beer_list],\n",
    "    'brewery_name': [brewery_list],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "relative-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler and OrdinalEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "outdoor-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, cats in cats_dict.items():\n",
    "    col_encoder = OrdinalEncoder(categories=cats)\n",
    "    df_cleaned[col] = col_encoder.fit_transform(df_cleaned[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "thick-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list called num_cols that contains all numeric columns\n",
    "### is scaler necessary? are there different ranges for these variables, or all 0-5?\n",
    "num_cols = ['review_aroma', 'review_appearance', 'review_palate', 'review_taste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hidden-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler and called it sc\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "varying-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the numeric features and replace the data into it\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "respective-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['beer_style'] = df_cleaned['beer_style'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "personalized-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.data.sets import split_sets_random, save_sets, pop_target\n",
    "\n",
    "def split_sets_random(df, target_col, test_ratio=0.2, to_numpy=False):\n",
    "    \"\"\"Split sets randomly\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    target_col : str\n",
    "        Name of the target column\n",
    "    test_ratio : float\n",
    "        Ratio used for the validation and testing sets (default: 0.2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        Features for the training set\n",
    "    Numpy Array\n",
    "        Target for the training set\n",
    "    Numpy Array\n",
    "        Features for the validation set\n",
    "    Numpy Array\n",
    "        Target for the validation set\n",
    "    Numpy Array\n",
    "        Features for the testing set\n",
    "    Numpy Array\n",
    "        Target for the testing set\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    features, target = pop_target(df=df, target_col=target_col, to_numpy=to_numpy)\n",
    "    \n",
    "    X_data, X_test, y_data, y_test = train_test_split(features, target, test_size=test_ratio, random_state=8)\n",
    "    \n",
    "    val_ratio = test_ratio / (1 - test_ratio)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=val_ratio, random_state=8)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "def save_sets(X_train=None, y_train=None, X_val=None, y_val=None, X_test=None, y_test=None, path='../data/processed/'):\n",
    "    import numpy as np\n",
    "\n",
    "    if X_train is not None:\n",
    "      np.save(f'{path}X_train', X_train)\n",
    "    if X_val is not None:\n",
    "      np.save(f'{path}X_val',   X_val)\n",
    "    if X_test is not None:\n",
    "      np.save(f'{path}X_test',  X_test)\n",
    "    if y_train is not None:\n",
    "      np.save(f'{path}y_train', y_train)\n",
    "    if y_val is not None:\n",
    "      np.save(f'{path}y_val',   y_val)\n",
    "    if y_test is not None:\n",
    "      np.save(f'{path}y_test',  y_test)\n",
    "    \n",
    "def pop_target(df, target_col, to_numpy=False):\n",
    "    \"\"\"Extract target variable from dataframe and convert to nympy arrays if required\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe\n",
    "    target_col : str\n",
    "        Name of the target variable\n",
    "    to_numpy : bool\n",
    "        Flag stating to convert to numpy array or not\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame/Numpy array\n",
    "        Subsetted Pandas dataframe containing all features\n",
    "    pd.DataFrame/Numpy array\n",
    "        Subsetted Pandas dataframe containing the target\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    target = df_copy.pop(target_col)\n",
    "    \n",
    "    if to_numpy:\n",
    "        df_copy = df_copy.to_numpy()\n",
    "        target = target.to_numpy()\n",
    "    \n",
    "    return df_copy, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ethical-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned, target_col='beer_style', test_ratio=0.2, to_numpy=True)\n",
    "\n",
    "# Save sets to folder\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "stuffed-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import this class from src/models/pytorch and convert all sets to PytorchDataset\n",
    "#from src.models.pytorch import PytorchDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "continued-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-escape",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "matched-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NullModel from src.models.null\n",
    "#from src.models.null import NullModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NullModel:\n",
    "    \"\"\"\n",
    "    Class used as baseline model for both regression and classification\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Type of ML problem (default regression)\n",
    "    y : Numpy Array-like\n",
    "        Target variable\n",
    "    pred_value : Float\n",
    "        Value to be used for prediction\n",
    "    preds : Numpy Array\n",
    "        Predicted array\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(y)\n",
    "        Store the input target variable and calculate the predicted value to be used based on the problem type\n",
    "    get_length\n",
    "        Calculate the number of observations from the target variable\n",
    "    predict(y)\n",
    "        Generate the predictions\n",
    "    fit_predict(y)\n",
    "        Perform a fit followed by predict\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    def __init__(self, target_type: str = \"regression\"):\n",
    "        self.target_type = target_type\n",
    "        self.y = None\n",
    "        self.pred_value = None\n",
    "        self.preds = None\n",
    "        \n",
    "    def fit(self, y):\n",
    "        self.y = y\n",
    "        if self.target_type == \"regression\":\n",
    "            self.pred_value = y.mean()\n",
    "        else:\n",
    "            from scipy.stats import mode\n",
    "            self.pred_value = mode(y)[0][0]\n",
    "            \n",
    "    def get_length(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def predict(self, y):\n",
    "        self.preds = np.full((self.get_length(), 1), self.pred_value)\n",
    "        return self.preds\n",
    "    \n",
    "    def fit_predict(self, y):\n",
    "        self.fit(y)\n",
    "        return self.predict(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "portable-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a NullModel and call .fit_predict() on the training target to extract your predictions into a variable called y_base\n",
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "general-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import print_class_perf from src.models.performance\n",
    "#from src.models.performance import print_class_perf\n",
    "\n",
    "def print_class_perf(y_preds, y_actuals, set_name=None, average='binary'):\n",
    "    \"\"\"Print the Accuracy and F1 score for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "    average : str\n",
    "        Parameter  for F1-score averaging\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    print(f\"Accuracy {set_name}: {accuracy_score(y_actuals, y_preds)}\")\n",
    "    print(f\"F1 {set_name}: {f1_score(y_actuals, y_preds, average=average)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "healthy-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.07430256975352931\n",
      "F1 Training: 0.01027805764859095\n"
     ]
    }
   ],
   "source": [
    "# # Task: Print the classification metrics for this baseline model\n",
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-syndicate",
   "metadata": {},
   "source": [
    "## Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "greenhouse-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "universal-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PytorchMultiClass with the correct number of input feature and save it into a variable called model\n",
    "#from src.models.pytorch import PytorchMultiClass\n",
    "\n",
    "class PytorchMultiClass(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchMultiClass, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 32)\n",
    "        self.layer_out = nn.Linear(32, 104) #Number of classes in target variable?\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)), training=self.training)\n",
    "        x = self.layer_out(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "prepared-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "received-passing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=5, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=104, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to use the device available\n",
    "#from src.models.pytorch import get_device\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "honest-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (layer_out): Linear(in_features=32, out_features=104, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the architecture of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-rough",
   "metadata": {},
   "source": [
    "## Create data loader (unnecessary?)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "front-china",
   "metadata": {},
   "source": [
    "from torch.utils.data import Dataset, Dataloader"
   ]
  },
  {
   "cell_type": "raw",
   "id": "mature-winner",
   "metadata": {},
   "source": [
    "#from src.models.pytorch import PytorchDataset\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "otherwise-intelligence",
   "metadata": {},
   "source": [
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "strategic-receipt",
   "metadata": {},
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_datset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-fitting",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "boolean-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a nn.CrossEntropyLoss() and save it into a variable called criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "decent-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a torch.optim.Adam() optimizer with the model's parameters and 0.1 as learning rate and save it into a variable called optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "vital-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called train_classification() that will perform forward and back propagation and calculate loss and Accuracy scores\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_classification(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, generate_batch=None):\n",
    "    \"\"\"Train a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class.long())\n",
    "\n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate global accuracy\n",
    "        train_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), train_acc / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "characteristic-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called test_classification() that will perform forward and calculate loss and accuracy scores\n",
    "def test_classification(test_data, model, criterion, batch_size, device, generate_batch=None):\n",
    "    \"\"\"Calculate performance of a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class.long())\n",
    "\n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            test_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    return test_loss / len(test_data), test_acc / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "immune-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 variables called N_EPOCHS and BATCH_SIZE that will take respectively 50 and 32 as values\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "optional-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.1446\t|\tAcc: 3.3%\n",
      "\t(valid)\t|\tLoss: 0.1448\t|\tAcc: 2.9%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.1441\t|\tAcc: 5.1%\n",
      "\t(valid)\t|\tLoss: 0.1448\t|\tAcc: 2.9%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.1445\t|\tAcc: 3.8%\n",
      "\t(valid)\t|\tLoss: 0.1448\t|\tAcc: 2.9%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.1446\t|\tAcc: 3.3%\n",
      "\t(valid)\t|\tLoss: 0.1448\t|\tAcc: 2.9%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.1446\t|\tAcc: 3.4%\n",
      "\t(valid)\t|\tLoss: 0.1448\t|\tAcc: 2.9%\n"
     ]
    }
   ],
   "source": [
    "# Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "veterinary-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model into the models folder\n",
    "torch.save(model, \"../models/pytorch_beer_pred.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-handling",
   "metadata": {},
   "source": [
    "## Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "blind-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.1447\t|\tAcc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Assess the model performance on the testing set and print its scores\n",
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAcc: {test_acc:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
